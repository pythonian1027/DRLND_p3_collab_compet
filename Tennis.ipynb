{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Tennis.app\"`\n",
    "- **Windows** (x86): `\"path/to/Tennis_Windows_x86/Tennis.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Tennis_Windows_x86_64/Tennis.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Tennis_Linux/Tennis.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Tennis_Linux/Tennis.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Tennis.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"C:\\\\Users\\\\ricor\\\\Google Drive\\\\developer\\\\python\\\\deep-reinforcement-learning\\\\p3_collab-compet\\\\Tennis_Windows_x86_64\\\\Tennis.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1.  If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01.  Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agents and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agents' performance, if they select actions at random with each time step.  A window should pop up that allows you to observe the agents.\n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agents are able to use their experiences to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: [[-0.97086262 -0.92388618]\n",
      " [-0.68993041 -1.        ]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[ 0.66797265  0.66580857]\n",
      " [ 0.32301401 -0.74278582]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[-0.0090758   0.61570413]\n",
      " [-1.         -0.20669259]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[ 1.          0.78063576]\n",
      " [-0.27483342 -0.78012279]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[ 1.          1.        ]\n",
      " [-0.88337533  1.        ]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[ 1.         -1.        ]\n",
      " [-0.11466493  0.80361473]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[-0.81472371  0.79886117]\n",
      " [-1.         -1.        ]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[1.         0.62386343]\n",
      " [0.52146467 0.76679137]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[-1.         0.6584958]\n",
      " [ 0.9507    -1.       ]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[-1.         -0.43621581]\n",
      " [-0.13217123 -0.42688401]]\n",
      "rewards: [0.0, 0.0]\n",
      "Score (max over agents) from episode 1: 0.0\n",
      "actions: [[-1.         -1.        ]\n",
      " [ 0.45624601 -1.        ]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[ 0.59372777 -0.22606693]\n",
      " [ 0.07099431 -1.        ]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[-0.84819396  0.68859509]\n",
      " [-1.         -1.        ]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[-0.1912309   1.        ]\n",
      " [ 0.26781568 -0.8373632 ]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[ 1.          1.        ]\n",
      " [ 0.40345208 -0.86636786]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[ 0.38628031 -1.        ]\n",
      " [-1.         -0.57526197]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[-0.60459591 -0.74791361]\n",
      " [ 0.31503264 -0.91188615]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[ 1.          0.17425047]\n",
      " [-1.          0.63363361]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[-0.24643043 -0.86283116]\n",
      " [ 1.         -0.20233747]]\n",
      "rewards: [0.0, -0.019999999552965164]\n",
      "Score (max over agents) from episode 2: 0.0\n",
      "actions: [[-0.63705262  0.30196392]\n",
      " [-1.         -1.        ]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[-0.43985605  0.14782958]\n",
      " [ 1.          0.04778457]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[-1.         -1.        ]\n",
      " [ 0.13729381 -1.        ]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[ 0.70142294  0.7010225 ]\n",
      " [ 0.79014358 -0.05362066]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[ 1.          1.        ]\n",
      " [ 0.81242667 -0.11760233]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[-0.70368703  0.61488768]\n",
      " [ 0.40373543 -0.30028376]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[1.         0.13064063]\n",
      " [0.61547477 1.        ]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[ 0.84478979  0.25700057]\n",
      " [-0.02723291 -1.        ]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[ 1.         -1.        ]\n",
      " [-1.          0.73827864]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[-1.          0.29696688]\n",
      " [-0.88674876 -0.82901014]]\n",
      "rewards: [0.0, 0.0]\n",
      "Score (max over agents) from episode 3: 0.0\n",
      "actions: [[-0.36399936  0.70665943]\n",
      " [ 0.10151784  0.6906094 ]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[ 0.65396723  0.11062898]\n",
      " [-0.69412734 -0.97889759]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[ 0.47021222 -0.47622261]\n",
      " [ 0.59969923 -0.39638453]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[ 0.0107875  -1.        ]\n",
      " [ 0.56139279  0.17770288]]\n",
      "rewards: [0.0, -0.009999999776482582]\n",
      "Score (max over agents) from episode 4: 0.0\n",
      "actions: [[-1.         -0.82828131]\n",
      " [ 0.27113942 -1.        ]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[-1.          0.72719743]\n",
      " [-1.          1.        ]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[ 0.77456008  1.        ]\n",
      " [ 0.69669527 -0.10981804]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[ 0.17263592 -0.12680585]\n",
      " [-1.         -0.65994995]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[ 0.18043177  1.        ]\n",
      " [-1.          0.00475095]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[ 1.         -1.        ]\n",
      " [ 1.          0.36916479]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[-0.66724705  0.41703817]\n",
      " [ 0.81327417  0.37910165]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[ 0.16620689  0.44016773]\n",
      " [-0.58157635 -0.5066238 ]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[ 0.96330441  0.08342677]\n",
      " [-1.         -0.55109717]]\n",
      "rewards: [0.0, 0.0]\n",
      "actions: [[-0.48838833 -0.83571448]\n",
      " [-1.          0.17529811]]\n",
      "rewards: [0.0, 0.0]\n",
      "Score (max over agents) from episode 5: 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):                                      # play game for 5 episodes\n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    for _ in range(10):\n",
    "#     while True:\n",
    "        actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "        actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "        print (\"actions: {}\".format(actions))\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        print (\"rewards: {}\".format(rewards))\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += env_info.rewards                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    print('Score (max over agents) from episode {}: {}'.format(i, np.max(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import workspace_utils\n",
    "import torch\n",
    "from ddpg_agent import Agent\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size=state_size, action_size=action_size, random_seed=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_multi_agent_ddpg(n_episodes = 20000, max_tsteps = 1500):\n",
    "    \"\"\"\n",
    "    DDPG algorithm\n",
    "        n_episodes: max number of episodes during training (int)\n",
    "        max_t: max number of timesteps (int)\n",
    "    \"\"\"\n",
    "    scores = list()    \n",
    "    rolling_window = deque(maxlen = 100) # mean score over last 100 instances    \n",
    "    mov_avg = list()\n",
    "    PRINT_EVERY = 1    \n",
    "    NUM_EPS_PERFORMANCE = 100    \n",
    "    TARGET_SCORE = 0.5\n",
    "    performance = -np.inf\n",
    "    \n",
    "    for ith_episode in range(1, n_episodes + 1): \n",
    "        agent.reset()\n",
    "        score = 0\n",
    "        scores_per_episode = np.zeros(num_agents)\n",
    "        env_info = env.reset(train_mode = True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for t_step in range(max_tsteps):\n",
    "            actions = agent.act(states)\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            rewards = env_info.rewards\n",
    "            next_states = env_info.vector_observations\n",
    "            dones = env_info.local_done\n",
    "            for state, action, reward, next_state, done in zip(states, actions, rewards, next_states, dones):\n",
    "                agent.step(state, action, reward, next_state, done, t_step)\n",
    "#             agent.step(states, actions, rewards, next_states, dones, t_step)\n",
    "            states = next_states\n",
    "            scores_per_episode += rewards            \n",
    "            \n",
    "            if np.any(dones):\n",
    "                break\n",
    "                \n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        # to get an estimation of the learning progress, we'll be using a moving average\n",
    "#         scores.append( list(scores_per_episode) )\n",
    "#         mov_avg.append(np.mean(scores[-NUM_EPS_PERFORMANCE:], axis = 0))\n",
    "\n",
    "        scores.append(np.max(scores_per_episode))\n",
    "        rolling_window.append(scores[-1])\n",
    "        mov_avg.append(np.mean(rolling_window))\n",
    "                \n",
    "        if not ith_episode % PRINT_EVERY:\n",
    "#             print (\"ma: {}\".format((mov_avg[-1])))\n",
    "#             print (\"score: {}\".format((scores[-1])))\n",
    "            print ('Episode: {:3d},\\tMovingAvg: {:.3f}\\tMaxScore: {:.3f}\\tElapsedTime: {}s' \\\n",
    "                    .format(ith_episode, mov_avg[-1], scores[-1], elapsed_time))\n",
    "    \n",
    "        if ith_episode >= NUM_EPS_PERFORMANCE and mov_avg[-1].mean() >= TARGET_SCORE:         \n",
    "            print (\"ENVIRONMENT SOLVED IN EPISODE : {}\".format(ith_episode))\n",
    "#             torch.save(agent.actor_local.state_dict(), 'checkpoint_actor_baseline.pth'.format(ith_episode))\n",
    "#             torch.save(agent.critic_local.state_dict(), 'checkpoint_critic_baseline.pth'.format(ith_episode))            \n",
    "            if mov_avg[-1].mean() > performance:\n",
    "                performance = mov_avg[-1].mean()\n",
    "                torch.save(agent.actor_local.state_dict(), 'checkpoint_actor_{}.pth'.format(ith_episode))\n",
    "                torch.save(agent.critic_local.state_dict(), 'checkpoint_critic_{}.pth'.format(ith_episode))            \n",
    "       \n",
    "        # PRINT RESULTS EVERY 10 EPISODES\n",
    "#         if not ith_episode % PRINT_EVERY:\n",
    "#             print(\"EPISODE: {},\\tAVG SCORE:: {:.2f}\".format(ith_episode, mov_avg[-1].mean()))\n",
    "    \n",
    "        \n",
    "    return scores, mov_avg                                                   \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:   1,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 3.06138014793396s\n",
      "Episode:   2,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.36307430267334s\n",
      "Episode:   3,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.249036073684692s\n",
      "Episode:   4,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.953890323638916s\n",
      "Episode:   5,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.56768012046814s\n",
      "Episode:   6,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.707520484924316s\n",
      "Episode:   7,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.7042076587677s\n",
      "Episode:   8,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.737839460372925s\n",
      "Episode:   9,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 7.233802080154419s\n",
      "Episode:  10,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.451153516769409s\n",
      "Episode:  11,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.655395269393921s\n",
      "Episode:  12,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.500123500823975s\n",
      "Episode:  13,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.597203731536865s\n",
      "Episode:  14,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.54097580909729s\n",
      "Episode:  15,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.643698692321777s\n",
      "Episode:  16,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 7.190166234970093s\n",
      "Episode:  17,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.854941129684448s\n",
      "Episode:  18,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.876132249832153s\n",
      "Episode:  19,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.965538740158081s\n",
      "Episode:  20,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.952406883239746s\n",
      "Episode:  21,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 7.313888311386108s\n",
      "Episode:  22,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.611718416213989s\n",
      "Episode:  23,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.666877508163452s\n",
      "Episode:  24,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.829053640365601s\n",
      "Episode:  25,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.581611394882202s\n",
      "Episode:  26,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 7.196430206298828s\n",
      "Episode:  27,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.806886911392212s\n",
      "Episode:  28,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.761410236358643s\n",
      "Episode:  29,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 7.005577564239502s\n",
      "Episode:  30,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.683396100997925s\n",
      "Episode:  31,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 7.262367248535156s\n",
      "Episode:  32,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.785610675811768s\n",
      "Episode:  33,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.74372673034668s\n",
      "Episode:  34,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.905351400375366s\n",
      "Episode:  35,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 7.016970872879028s\n",
      "Episode:  36,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 7.407400846481323s\n",
      "Episode:  37,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.767515420913696s\n",
      "Episode:  38,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 7.0237627029418945s\n",
      "Episode:  39,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.932138919830322s\n",
      "Episode:  40,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 6.850727796554565s\n",
      "Episode:  41,\tMovingAvg: 0.000\tMaxScore: 0.000\tElapsedTime: 7.310155868530273s\n",
      "Episode:  42,\tMovingAvg: 0.002\tMaxScore: 0.100\tElapsedTime: 16.284290552139282s\n",
      "Episode:  43,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 7.016982793807983s\n",
      "Episode:  44,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 7.041755437850952s\n",
      "Episode:  45,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 6.975665807723999s\n",
      "Episode:  46,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 7.423058032989502s\n",
      "Episode:  47,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 7.187011480331421s\n",
      "Episode:  48,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 6.80353569984436s\n",
      "Episode:  49,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 6.978647947311401s\n",
      "Episode:  50,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 6.8463454246521s\n",
      "Episode:  51,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 7.275295972824097s\n",
      "Episode:  52,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 7.154016494750977s\n",
      "Episode:  53,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 7.004687070846558s\n",
      "Episode:  54,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 6.853937864303589s\n",
      "Episode:  55,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 6.803771018981934s\n",
      "Episode:  56,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 7.414291143417358s\n",
      "Episode:  57,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 7.143836975097656s\n",
      "Episode:  58,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 7.429843902587891s\n",
      "Episode:  59,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 7.18751335144043s\n",
      "Episode:  60,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 7.181929349899292s\n",
      "Episode:  61,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 7.564540863037109s\n",
      "Episode:  62,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 6.893336057662964s\n",
      "Episode:  63,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 7.154210329055786s\n",
      "Episode:  64,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 6.946674823760986s\n",
      "Episode:  65,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 6.902799606323242s\n",
      "Episode:  66,\tMovingAvg: 0.002\tMaxScore: 0.000\tElapsedTime: 7.3957531452178955s\n",
      "Episode:  67,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 7.051475286483765s\n",
      "Episode:  68,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 7.255847215652466s\n",
      "Episode:  69,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.89072322845459s\n",
      "Episode:  70,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.976417303085327s\n",
      "Episode:  71,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 7.312056541442871s\n",
      "Episode:  72,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 7.109360694885254s\n",
      "Episode:  73,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 7.315382242202759s\n",
      "Episode:  74,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 7.167271137237549s\n",
      "Episode:  75,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.944299936294556s\n",
      "Episode:  76,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 7.377504348754883s\n",
      "Episode:  77,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.91798734664917s\n",
      "Episode:  78,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 7.012956380844116s\n",
      "Episode:  79,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.781083583831787s\n",
      "Episode:  80,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.7399890422821045s\n",
      "Episode:  81,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 7.450756788253784s\n",
      "Episode:  82,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.805922985076904s\n",
      "Episode:  83,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 7.043712615966797s\n",
      "Episode:  84,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.90693998336792s\n",
      "Episode:  85,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.864489316940308s\n",
      "Episode:  86,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 7.199642896652222s\n",
      "Episode:  87,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.81938910484314s\n",
      "Episode:  88,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.936066627502441s\n",
      "Episode:  89,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.842288494110107s\n",
      "Episode:  90,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.8343987464904785s\n",
      "Episode:  91,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 7.2370195388793945s\n",
      "Episode:  92,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.823289155960083s\n",
      "Episode:  93,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 7.0331809520721436s\n",
      "Episode:  94,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.914473295211792s\n",
      "Episode:  95,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 8.277615547180176s\n",
      "Episode:  96,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 7.452377080917358s\n",
      "Episode:  97,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.894927024841309s\n",
      "Episode:  98,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.87567138671875s\n",
      "Episode:  99,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 7.234126567840576s\n",
      "Episode: 100,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.759771108627319s\n",
      "Episode: 101,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.834207773208618s\n",
      "Episode: 102,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.893474817276001s\n",
      "Episode: 103,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.84421443939209s\n",
      "Episode: 104,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 7.536585569381714s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 105,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.959812879562378s\n",
      "Episode: 106,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.795757293701172s\n",
      "Episode: 107,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 7.021543979644775s\n",
      "Episode: 108,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.839001655578613s\n",
      "Episode: 109,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 7.274679183959961s\n",
      "Episode: 110,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.851777076721191s\n",
      "Episode: 111,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.722318172454834s\n",
      "Episode: 112,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.942230939865112s\n",
      "Episode: 113,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.843378305435181s\n",
      "Episode: 114,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 7.199160575866699s\n",
      "Episode: 115,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.946721315383911s\n",
      "Episode: 116,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.929791212081909s\n",
      "Episode: 117,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.9138524532318115s\n",
      "Episode: 118,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.932108640670776s\n",
      "Episode: 119,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 7.251842975616455s\n",
      "Episode: 120,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.794529914855957s\n",
      "Episode: 121,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.734057903289795s\n",
      "Episode: 122,\tMovingAvg: 0.001\tMaxScore: 0.000\tElapsedTime: 6.924175262451172s\n",
      "Episode: 123,\tMovingAvg: 0.002\tMaxScore: 0.090\tElapsedTime: 15.597836971282959s\n",
      "Episode: 124,\tMovingAvg: 0.003\tMaxScore: 0.090\tElapsedTime: 14.646975040435791s\n",
      "Episode: 125,\tMovingAvg: 0.004\tMaxScore: 0.090\tElapsedTime: 15.975929498672485s\n",
      "Episode: 126,\tMovingAvg: 0.005\tMaxScore: 0.090\tElapsedTime: 14.819499731063843s\n",
      "Episode: 127,\tMovingAvg: 0.006\tMaxScore: 0.100\tElapsedTime: 15.808573961257935s\n",
      "Episode: 128,\tMovingAvg: 0.007\tMaxScore: 0.100\tElapsedTime: 25.346729040145874s\n",
      "Episode: 129,\tMovingAvg: 0.008\tMaxScore: 0.090\tElapsedTime: 15.246363162994385s\n",
      "Episode: 130,\tMovingAvg: 0.009\tMaxScore: 0.100\tElapsedTime: 15.556442975997925s\n",
      "Episode: 131,\tMovingAvg: 0.009\tMaxScore: 0.000\tElapsedTime: 9.008922338485718s\n",
      "Episode: 132,\tMovingAvg: 0.010\tMaxScore: 0.100\tElapsedTime: 16.05904269218445s\n",
      "Episode: 133,\tMovingAvg: 0.010\tMaxScore: 0.000\tElapsedTime: 6.870788812637329s\n",
      "Episode: 134,\tMovingAvg: 0.011\tMaxScore: 0.100\tElapsedTime: 16.408759117126465s\n",
      "Episode: 135,\tMovingAvg: 0.012\tMaxScore: 0.100\tElapsedTime: 16.272608757019043s\n",
      "Episode: 136,\tMovingAvg: 0.013\tMaxScore: 0.100\tElapsedTime: 24.68186926841736s\n",
      "Episode: 137,\tMovingAvg: 0.013\tMaxScore: 0.090\tElapsedTime: 15.415848970413208s\n",
      "Episode: 138,\tMovingAvg: 0.014\tMaxScore: 0.100\tElapsedTime: 16.403131008148193s\n",
      "Episode: 139,\tMovingAvg: 0.015\tMaxScore: 0.090\tElapsedTime: 15.975109577178955s\n",
      "Episode: 140,\tMovingAvg: 0.016\tMaxScore: 0.100\tElapsedTime: 21.11749792098999s\n",
      "Episode: 141,\tMovingAvg: 0.018\tMaxScore: 0.200\tElapsedTime: 30.399489879608154s\n",
      "Episode: 142,\tMovingAvg: 0.018\tMaxScore: 0.100\tElapsedTime: 25.16566300392151s\n",
      "Episode: 143,\tMovingAvg: 0.019\tMaxScore: 0.100\tElapsedTime: 25.335078954696655s\n",
      "Episode: 144,\tMovingAvg: 0.020\tMaxScore: 0.090\tElapsedTime: 14.879507064819336s\n",
      "Episode: 145,\tMovingAvg: 0.022\tMaxScore: 0.200\tElapsedTime: 34.744733572006226s\n",
      "Episode: 146,\tMovingAvg: 0.022\tMaxScore: 0.000\tElapsedTime: 6.331967115402222s\n",
      "Episode: 147,\tMovingAvg: 0.023\tMaxScore: 0.100\tElapsedTime: 15.175540447235107s\n",
      "Episode: 148,\tMovingAvg: 0.023\tMaxScore: 0.000\tElapsedTime: 6.704304456710815s\n",
      "Episode: 149,\tMovingAvg: 0.024\tMaxScore: 0.100\tElapsedTime: 25.6222083568573s\n",
      "Episode: 150,\tMovingAvg: 0.025\tMaxScore: 0.100\tElapsedTime: 15.08531665802002s\n",
      "Episode: 151,\tMovingAvg: 0.026\tMaxScore: 0.100\tElapsedTime: 15.201846361160278s\n",
      "Episode: 152,\tMovingAvg: 0.027\tMaxScore: 0.100\tElapsedTime: 14.96192455291748s\n",
      "Episode: 153,\tMovingAvg: 0.028\tMaxScore: 0.090\tElapsedTime: 14.698149681091309s\n",
      "Episode: 154,\tMovingAvg: 0.029\tMaxScore: 0.090\tElapsedTime: 14.33896017074585s\n",
      "Episode: 155,\tMovingAvg: 0.029\tMaxScore: 0.000\tElapsedTime: 7.624553203582764s\n",
      "Episode: 156,\tMovingAvg: 0.029\tMaxScore: 0.000\tElapsedTime: 6.9332921504974365s\n",
      "Episode: 157,\tMovingAvg: 0.030\tMaxScore: 0.100\tElapsedTime: 14.411353826522827s\n",
      "Episode: 158,\tMovingAvg: 0.037\tMaxScore: 0.700\tElapsedTime: 147.71773743629456s\n",
      "Episode: 159,\tMovingAvg: 0.038\tMaxScore: 0.100\tElapsedTime: 15.428772211074829s\n",
      "Episode: 160,\tMovingAvg: 0.040\tMaxScore: 0.200\tElapsedTime: 35.830137968063354s\n",
      "Episode: 161,\tMovingAvg: 0.041\tMaxScore: 0.090\tElapsedTime: 14.95428204536438s\n",
      "Episode: 162,\tMovingAvg: 0.042\tMaxScore: 0.100\tElapsedTime: 25.800130605697632s\n",
      "Episode: 163,\tMovingAvg: 0.043\tMaxScore: 0.100\tElapsedTime: 15.095394611358643s\n",
      "Episode: 164,\tMovingAvg: 0.044\tMaxScore: 0.100\tElapsedTime: 25.77940320968628s\n",
      "Episode: 165,\tMovingAvg: 0.045\tMaxScore: 0.100\tElapsedTime: 14.703326225280762s\n",
      "Episode: 166,\tMovingAvg: 0.046\tMaxScore: 0.100\tElapsedTime: 15.578633546829224s\n",
      "Episode: 167,\tMovingAvg: 0.047\tMaxScore: 0.100\tElapsedTime: 14.960467100143433s\n",
      "Episode: 168,\tMovingAvg: 0.048\tMaxScore: 0.100\tElapsedTime: 14.957430839538574s\n",
      "Episode: 169,\tMovingAvg: 0.049\tMaxScore: 0.100\tElapsedTime: 14.827303647994995s\n",
      "Episode: 170,\tMovingAvg: 0.050\tMaxScore: 0.100\tElapsedTime: 15.141600370407104s\n",
      "Episode: 171,\tMovingAvg: 0.051\tMaxScore: 0.100\tElapsedTime: 29.542487859725952s\n",
      "Episode: 172,\tMovingAvg: 0.053\tMaxScore: 0.190\tElapsedTime: 34.914406299591064s\n",
      "Episode: 173,\tMovingAvg: 0.054\tMaxScore: 0.100\tElapsedTime: 15.195341348648071s\n",
      "Episode: 174,\tMovingAvg: 0.055\tMaxScore: 0.100\tElapsedTime: 17.33889865875244s\n",
      "Episode: 175,\tMovingAvg: 0.056\tMaxScore: 0.100\tElapsedTime: 25.44874620437622s\n",
      "Episode: 176,\tMovingAvg: 0.057\tMaxScore: 0.090\tElapsedTime: 15.461384773254395s\n",
      "Episode: 177,\tMovingAvg: 0.058\tMaxScore: 0.100\tElapsedTime: 15.158865451812744s\n",
      "Episode: 178,\tMovingAvg: 0.063\tMaxScore: 0.500\tElapsedTime: 102.04143929481506s\n",
      "Episode: 179,\tMovingAvg: 0.064\tMaxScore: 0.100\tElapsedTime: 25.77825117111206s\n",
      "Episode: 180,\tMovingAvg: 0.065\tMaxScore: 0.100\tElapsedTime: 25.473336696624756s\n",
      "Episode: 181,\tMovingAvg: 0.065\tMaxScore: 0.000\tElapsedTime: 7.167763948440552s\n",
      "Episode: 182,\tMovingAvg: 0.066\tMaxScore: 0.090\tElapsedTime: 15.201923131942749s\n",
      "Episode: 183,\tMovingAvg: 0.067\tMaxScore: 0.100\tElapsedTime: 23.954024076461792s\n",
      "Episode: 184,\tMovingAvg: 0.068\tMaxScore: 0.100\tElapsedTime: 25.989943265914917s\n",
      "Episode: 185,\tMovingAvg: 0.068\tMaxScore: 0.000\tElapsedTime: 7.148984909057617s\n",
      "Episode: 186,\tMovingAvg: 0.068\tMaxScore: 0.000\tElapsedTime: 9.021391153335571s\n",
      "Episode: 187,\tMovingAvg: 0.069\tMaxScore: 0.100\tElapsedTime: 24.037421703338623s\n",
      "Episode: 188,\tMovingAvg: 0.072\tMaxScore: 0.300\tElapsedTime: 53.99914002418518s\n",
      "Episode: 189,\tMovingAvg: 0.074\tMaxScore: 0.200\tElapsedTime: 36.1675910949707s\n",
      "Episode: 190,\tMovingAvg: 0.077\tMaxScore: 0.290\tElapsedTime: 52.65339183807373s\n",
      "Episode: 191,\tMovingAvg: 0.078\tMaxScore: 0.100\tElapsedTime: 15.8861722946167s\n",
      "Episode: 192,\tMovingAvg: 0.079\tMaxScore: 0.100\tElapsedTime: 28.20014238357544s\n",
      "Episode: 193,\tMovingAvg: 0.082\tMaxScore: 0.300\tElapsedTime: 54.139652967453s\n",
      "Episode: 194,\tMovingAvg: 0.084\tMaxScore: 0.200\tElapsedTime: 54.999401807785034s\n",
      "Episode: 195,\tMovingAvg: 0.085\tMaxScore: 0.100\tElapsedTime: 26.61598300933838s\n",
      "Episode: 196,\tMovingAvg: 0.086\tMaxScore: 0.100\tElapsedTime: 16.67520022392273s\n",
      "Episode: 197,\tMovingAvg: 0.088\tMaxScore: 0.200\tElapsedTime: 46.004798412323s\n",
      "Episode: 198,\tMovingAvg: 0.089\tMaxScore: 0.100\tElapsedTime: 25.74803328514099s\n",
      "Episode: 199,\tMovingAvg: 0.090\tMaxScore: 0.100\tElapsedTime: 26.031235218048096s\n",
      "Episode: 200,\tMovingAvg: 0.091\tMaxScore: 0.100\tElapsedTime: 15.200482606887817s\n",
      "Episode: 201,\tMovingAvg: 0.092\tMaxScore: 0.100\tElapsedTime: 15.11048173904419s\n",
      "Episode: 202,\tMovingAvg: 0.093\tMaxScore: 0.190\tElapsedTime: 34.183435678482056s\n",
      "Episode: 203,\tMovingAvg: 0.097\tMaxScore: 0.390\tElapsedTime: 76.51530599594116s\n",
      "Episode: 204,\tMovingAvg: 0.097\tMaxScore: 0.000\tElapsedTime: 8.103655099868774s\n",
      "Episode: 205,\tMovingAvg: 0.097\tMaxScore: 0.000\tElapsedTime: 6.872305870056152s\n",
      "Episode: 206,\tMovingAvg: 0.097\tMaxScore: 0.000\tElapsedTime: 7.026555299758911s\n",
      "Episode: 207,\tMovingAvg: 0.098\tMaxScore: 0.100\tElapsedTime: 25.964850425720215s\n",
      "Episode: 208,\tMovingAvg: 0.099\tMaxScore: 0.100\tElapsedTime: 25.6227810382843s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 209,\tMovingAvg: 0.101\tMaxScore: 0.200\tElapsedTime: 43.745688915252686s\n",
      "Episode: 210,\tMovingAvg: 0.101\tMaxScore: 0.000\tElapsedTime: 7.3044397830963135s\n",
      "Episode: 211,\tMovingAvg: 0.102\tMaxScore: 0.100\tElapsedTime: 24.965827465057373s\n",
      "Episode: 212,\tMovingAvg: 0.104\tMaxScore: 0.200\tElapsedTime: 44.79218029975891s\n",
      "Episode: 213,\tMovingAvg: 0.104\tMaxScore: 0.000\tElapsedTime: 6.793846130371094s\n",
      "Episode: 214,\tMovingAvg: 0.106\tMaxScore: 0.200\tElapsedTime: 44.45792198181152s\n",
      "Episode: 215,\tMovingAvg: 0.108\tMaxScore: 0.200\tElapsedTime: 43.16961932182312s\n",
      "Episode: 216,\tMovingAvg: 0.110\tMaxScore: 0.200\tElapsedTime: 47.85085201263428s\n",
      "Episode: 217,\tMovingAvg: 0.111\tMaxScore: 0.100\tElapsedTime: 15.876285314559937s\n",
      "Episode: 218,\tMovingAvg: 0.112\tMaxScore: 0.100\tElapsedTime: 16.88001298904419s\n",
      "Episode: 219,\tMovingAvg: 0.113\tMaxScore: 0.100\tElapsedTime: 19.85245180130005s\n",
      "Episode: 220,\tMovingAvg: 0.114\tMaxScore: 0.100\tElapsedTime: 16.199029445648193s\n",
      "Episode: 221,\tMovingAvg: 0.115\tMaxScore: 0.100\tElapsedTime: 25.09249997138977s\n",
      "Episode: 222,\tMovingAvg: 0.116\tMaxScore: 0.100\tElapsedTime: 15.453064918518066s\n",
      "Episode: 223,\tMovingAvg: 0.116\tMaxScore: 0.100\tElapsedTime: 24.807403564453125s\n",
      "Episode: 224,\tMovingAvg: 0.117\tMaxScore: 0.190\tElapsedTime: 30.324966430664062s\n",
      "Episode: 225,\tMovingAvg: 0.118\tMaxScore: 0.100\tElapsedTime: 14.720102071762085s\n",
      "Episode: 226,\tMovingAvg: 0.118\tMaxScore: 0.100\tElapsedTime: 15.062780857086182s\n",
      "Episode: 227,\tMovingAvg: 0.118\tMaxScore: 0.100\tElapsedTime: 14.728975534439087s\n",
      "Episode: 228,\tMovingAvg: 0.118\tMaxScore: 0.100\tElapsedTime: 15.154644966125488s\n",
      "Episode: 229,\tMovingAvg: 0.120\tMaxScore: 0.300\tElapsedTime: 53.010923624038696s\n",
      "Episode: 230,\tMovingAvg: 0.124\tMaxScore: 0.500\tElapsedTime: 100.05764842033386s\n",
      "Episode: 231,\tMovingAvg: 0.125\tMaxScore: 0.100\tElapsedTime: 15.168570280075073s\n",
      "Episode: 232,\tMovingAvg: 0.125\tMaxScore: 0.090\tElapsedTime: 14.757002592086792s\n",
      "Episode: 233,\tMovingAvg: 0.126\tMaxScore: 0.100\tElapsedTime: 15.194823741912842s\n",
      "Episode: 234,\tMovingAvg: 0.126\tMaxScore: 0.090\tElapsedTime: 14.67842411994934s\n",
      "Episode: 235,\tMovingAvg: 0.126\tMaxScore: 0.100\tElapsedTime: 14.71168065071106s\n",
      "Episode: 236,\tMovingAvg: 0.126\tMaxScore: 0.100\tElapsedTime: 15.16458797454834s\n",
      "Episode: 237,\tMovingAvg: 0.127\tMaxScore: 0.200\tElapsedTime: 35.07492756843567s\n",
      "Episode: 238,\tMovingAvg: 0.127\tMaxScore: 0.100\tElapsedTime: 15.161005973815918s\n",
      "Episode: 239,\tMovingAvg: 0.129\tMaxScore: 0.300\tElapsedTime: 53.465086221694946s\n",
      "Episode: 240,\tMovingAvg: 0.129\tMaxScore: 0.100\tElapsedTime: 24.27377486228943s\n",
      "Episode: 241,\tMovingAvg: 0.133\tMaxScore: 0.600\tElapsedTime: 110.27432131767273s\n",
      "Episode: 242,\tMovingAvg: 0.137\tMaxScore: 0.500\tElapsedTime: 103.1468620300293s\n",
      "Episode: 243,\tMovingAvg: 0.137\tMaxScore: 0.100\tElapsedTime: 17.256643772125244s\n",
      "Episode: 244,\tMovingAvg: 0.138\tMaxScore: 0.200\tElapsedTime: 42.97969841957092s\n",
      "Episode: 245,\tMovingAvg: 0.137\tMaxScore: 0.100\tElapsedTime: 15.044086933135986s\n",
      "Episode: 246,\tMovingAvg: 0.139\tMaxScore: 0.200\tElapsedTime: 36.43083620071411s\n",
      "Episode: 247,\tMovingAvg: 0.139\tMaxScore: 0.100\tElapsedTime: 16.386374473571777s\n",
      "Episode: 248,\tMovingAvg: 0.141\tMaxScore: 0.200\tElapsedTime: 37.19515585899353s\n",
      "Episode: 249,\tMovingAvg: 0.142\tMaxScore: 0.200\tElapsedTime: 57.07977557182312s\n",
      "Episode: 250,\tMovingAvg: 0.142\tMaxScore: 0.100\tElapsedTime: 16.53546714782715s\n",
      "Episode: 251,\tMovingAvg: 0.144\tMaxScore: 0.300\tElapsedTime: 55.515990018844604s\n",
      "Episode: 252,\tMovingAvg: 0.144\tMaxScore: 0.100\tElapsedTime: 26.663183450698853s\n",
      "Episode: 253,\tMovingAvg: 0.144\tMaxScore: 0.100\tElapsedTime: 27.975524187088013s\n",
      "Episode: 254,\tMovingAvg: 0.144\tMaxScore: 0.100\tElapsedTime: 26.7487633228302s\n",
      "Episode: 255,\tMovingAvg: 0.147\tMaxScore: 0.300\tElapsedTime: 64.74124693870544s\n",
      "Episode: 256,\tMovingAvg: 0.148\tMaxScore: 0.100\tElapsedTime: 25.39726233482361s\n",
      "Episode: 257,\tMovingAvg: 0.149\tMaxScore: 0.200\tElapsedTime: 44.525827169418335s\n",
      "Episode: 258,\tMovingAvg: 0.147\tMaxScore: 0.500\tElapsedTime: 95.0178050994873s\n",
      "Episode: 259,\tMovingAvg: 0.149\tMaxScore: 0.300\tElapsedTime: 61.24458694458008s\n",
      "Episode: 260,\tMovingAvg: 0.150\tMaxScore: 0.300\tElapsedTime: 52.0741822719574s\n",
      "Episode: 261,\tMovingAvg: 0.151\tMaxScore: 0.200\tElapsedTime: 41.891905546188354s\n",
      "Episode: 262,\tMovingAvg: 0.151\tMaxScore: 0.100\tElapsedTime: 24.59790539741516s\n",
      "Episode: 263,\tMovingAvg: 0.155\tMaxScore: 0.500\tElapsedTime: 89.1663932800293s\n",
      "Episode: 264,\tMovingAvg: 0.157\tMaxScore: 0.300\tElapsedTime: 60.353012800216675s\n",
      "Episode: 265,\tMovingAvg: 0.157\tMaxScore: 0.090\tElapsedTime: 13.985866785049438s\n",
      "Episode: 266,\tMovingAvg: 0.158\tMaxScore: 0.200\tElapsedTime: 43.06701350212097s\n",
      "Episode: 267,\tMovingAvg: 0.158\tMaxScore: 0.100\tElapsedTime: 14.832447052001953s\n",
      "Episode: 268,\tMovingAvg: 0.158\tMaxScore: 0.100\tElapsedTime: 16.701539039611816s\n",
      "Episode: 269,\tMovingAvg: 0.158\tMaxScore: 0.100\tElapsedTime: 14.849447250366211s\n",
      "Episode: 270,\tMovingAvg: 0.158\tMaxScore: 0.100\tElapsedTime: 34.45513296127319s\n",
      "Episode: 271,\tMovingAvg: 0.158\tMaxScore: 0.100\tElapsedTime: 15.451534032821655s\n",
      "Episode: 272,\tMovingAvg: 0.157\tMaxScore: 0.100\tElapsedTime: 14.481107711791992s\n",
      "Episode: 273,\tMovingAvg: 0.165\tMaxScore: 0.900\tElapsedTime: 160.63405871391296s\n",
      "Episode: 274,\tMovingAvg: 0.168\tMaxScore: 0.400\tElapsedTime: 68.89937138557434s\n",
      "Episode: 275,\tMovingAvg: 0.169\tMaxScore: 0.200\tElapsedTime: 41.16855049133301s\n",
      "Episode: 276,\tMovingAvg: 0.169\tMaxScore: 0.100\tElapsedTime: 31.173770427703857s\n",
      "Episode: 277,\tMovingAvg: 0.183\tMaxScore: 1.500\tElapsedTime: 281.97594594955444s\n",
      "Episode: 278,\tMovingAvg: 0.179\tMaxScore: 0.100\tElapsedTime: 25.527814865112305s\n",
      "Episode: 279,\tMovingAvg: 0.179\tMaxScore: 0.100\tElapsedTime: 17.7057843208313s\n",
      "Episode: 280,\tMovingAvg: 0.194\tMaxScore: 1.600\tElapsedTime: 301.9846308231354s\n",
      "Episode: 281,\tMovingAvg: 0.195\tMaxScore: 0.100\tElapsedTime: 25.585729598999023s\n",
      "Episode: 282,\tMovingAvg: 0.201\tMaxScore: 0.700\tElapsedTime: 135.06046557426453s\n",
      "Episode: 283,\tMovingAvg: 0.212\tMaxScore: 1.200\tElapsedTime: 218.2297854423523s\n",
      "Episode: 284,\tMovingAvg: 0.212\tMaxScore: 0.100\tElapsedTime: 29.783282041549683s\n",
      "Episode: 285,\tMovingAvg: 0.238\tMaxScore: 2.600\tElapsedTime: 478.65669465065s\n",
      "Episode: 286,\tMovingAvg: 0.249\tMaxScore: 1.100\tElapsedTime: 211.66219687461853s\n",
      "Episode: 287,\tMovingAvg: 0.250\tMaxScore: 0.200\tElapsedTime: 44.53972887992859s\n",
      "Episode: 288,\tMovingAvg: 0.249\tMaxScore: 0.200\tElapsedTime: 33.406676292419434s\n",
      "Episode: 289,\tMovingAvg: 0.249\tMaxScore: 0.200\tElapsedTime: 35.4881386756897s\n",
      "Episode: 290,\tMovingAvg: 0.251\tMaxScore: 0.500\tElapsedTime: 98.48194885253906s\n",
      "Episode: 291,\tMovingAvg: 0.250\tMaxScore: 0.000\tElapsedTime: 7.366768836975098s\n",
      "Episode: 292,\tMovingAvg: 0.251\tMaxScore: 0.200\tElapsedTime: 44.53843402862549s\n",
      "Episode: 293,\tMovingAvg: 0.264\tMaxScore: 1.600\tElapsedTime: 312.6419026851654s\n",
      "Episode: 294,\tMovingAvg: 0.265\tMaxScore: 0.300\tElapsedTime: 61.83008646965027s\n",
      "Episode: 295,\tMovingAvg: 0.266\tMaxScore: 0.200\tElapsedTime: 41.49649381637573s\n",
      "Episode: 296,\tMovingAvg: 0.283\tMaxScore: 1.800\tElapsedTime: 339.03309655189514s\n",
      "Episode: 297,\tMovingAvg: 0.307\tMaxScore: 2.600\tElapsedTime: 478.60044598579407s\n",
      "Episode: 298,\tMovingAvg: 0.321\tMaxScore: 1.500\tElapsedTime: 268.16176438331604s\n",
      "Episode: 299,\tMovingAvg: 0.327\tMaxScore: 0.700\tElapsedTime: 134.8006021976471s\n",
      "Episode: 300,\tMovingAvg: 0.328\tMaxScore: 0.190\tElapsedTime: 32.026161193847656s\n",
      "Episode: 301,\tMovingAvg: 0.329\tMaxScore: 0.200\tElapsedTime: 32.48022246360779s\n",
      "Episode: 302,\tMovingAvg: 0.328\tMaxScore: 0.090\tElapsedTime: 14.428395509719849s\n",
      "Episode: 303,\tMovingAvg: 0.325\tMaxScore: 0.100\tElapsedTime: 15.381647825241089s\n",
      "Episode: 304,\tMovingAvg: 0.326\tMaxScore: 0.100\tElapsedTime: 24.74729561805725s\n",
      "Episode: 305,\tMovingAvg: 0.327\tMaxScore: 0.100\tElapsedTime: 25.803648948669434s\n",
      "Episode: 306,\tMovingAvg: 0.342\tMaxScore: 1.500\tElapsedTime: 284.0104150772095s\n",
      "Episode: 307,\tMovingAvg: 0.367\tMaxScore: 2.600\tElapsedTime: 478.9666199684143s\n",
      "Episode: 308,\tMovingAvg: 0.370\tMaxScore: 0.400\tElapsedTime: 67.60818409919739s\n",
      "Episode: 309,\tMovingAvg: 0.392\tMaxScore: 2.400\tElapsedTime: 453.92282581329346s\n",
      "Episode: 310,\tMovingAvg: 0.418\tMaxScore: 2.600\tElapsedTime: 482.57067608833313s\n",
      "Episode: 311,\tMovingAvg: 0.443\tMaxScore: 2.600\tElapsedTime: 481.1617200374603s\n",
      "Episode: 312,\tMovingAvg: 0.460\tMaxScore: 1.900\tElapsedTime: 340.22730135917664s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 313,\tMovingAvg: 0.486\tMaxScore: 2.600\tElapsedTime: 480.1114909648895s\n",
      "Episode: 314,\tMovingAvg: 0.498\tMaxScore: 1.400\tElapsedTime: 255.9455361366272s\n",
      "Episode: 315,\tMovingAvg: 0.503\tMaxScore: 0.700\tElapsedTime: 127.80626559257507s\n",
      "ENVIRONMENT SOLVED IN EPISODE : 315\n",
      "done!\n",
      "Wall time: 3h 29min 36s\n"
     ]
    }
   ],
   "source": [
    "%time scores, mov_avg = train_multi_agent_ddpg()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "results = {'scores': scores, 'movavg': mov_avg}\n",
    "with open('ddpg_tennis_results', 'wb') as f:\n",
    "    pickle.dump(results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e7b77df160>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TARGET_SCORE = 0.5\n",
    "#create horizonal line indicating minimum goal level\n",
    "target = [TARGET_SCORE] * len(scores)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title('DDPG Tennis Multiagent Learning Performance')\n",
    "ax.plot(scores, label = 'Score', color = 'blue', )\n",
    "ax.plot(mov_avg, label = 'Mov. Avg', color = 'orangered', linestyle='-', )\n",
    "ax.hlines(y = 0.5, xmin = 0, xmax = len(scores), linestyle = '--', color = 'red', label = 'GOAL')\n",
    "ax.grid()\n",
    "ax.set_xlabel('# episodes')\n",
    "ax.set_ylabel('scores')\n",
    "plt.legend()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
